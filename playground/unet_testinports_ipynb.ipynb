{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac7029",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from testimports import CustomImageDataset\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "data_dir = os.path.join(script_dir, '../data')\n",
    "duitu_root = os.path.abspath(os.path.join(script_dir, \"..\"))\n",
    "\n",
    "# Add DUITU to the Python path\n",
    "sys.path.append(duitu_root)\n",
    "from models.Unet import UNet\n",
    "from models.UNetKernelSize import UNetKernelSize\n",
    "from scripts.dataloader import get_dataloaders\n",
    "\n",
    "# Enable cuDNN benchmark\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Enhanced transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomImageDataset(\n",
    "    images_dir=os.path.join(data_dir, 'train'),\n",
    "    labels_dir=os.path.join(data_dir, 'train_labels'),\n",
    "    class_dict_csv=os.path.join(data_dir, 'class_dict.csv'),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Optimized DataLoader config\n",
    "train_loader, val_loader, test_loader, class_dict = get_dataloaders()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNetKernelSize(in_channels=3, num_classes=32, kernel_size=7)\n",
    "\n",
    "# Use smaller bottleneck in UNet (modify your UNet class)\n",
    "# Original: self.bottle_neck = DoubleConv(512, 1024)\n",
    "# Change to: self.bottle_neck = DoubleConv(512, 512)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, device, epochs=10):\n",
    "    model.to(device)\n",
    "\n",
    "    epoch_loop = tqdm(range(epochs), desc=\"🔁 Epochs\", bar_format=\"{l_bar}{bar} | Epoch {n_fmt}/{total_fmt} | Elapsed: {elapsed} | Remaining: {remaining}\")\n",
    "    for epoch in epoch_loop:\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Training loop\n",
    "        early_stopping_counter = 0\n",
    "        train_loop = tqdm(train_loader, desc=f\"📊 Training.     Current loss: {running_loss} \", leave=False, \n",
    "                     bar_format=\"{l_bar}{bar} | {n_fmt}/{total_fmt} batches | Elapsed: {elapsed} | Remaining: {remaining}\")\n",
    "        for images, masks in train_loop:\n",
    "                \n",
    "            # Faster data transfer\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True).float()\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)  # More efficient\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            early_stopping_counter += 1\n",
    "            train_loop.set_description(f\"📊 Training. Current Avg. loss: {(running_loss / early_stopping_counter):.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            early_stopping_counter = 0\n",
    "            val_loop = tqdm(val_loader, desc=\"Validating\", leave=False,\n",
    "                       bar_format=\"{l_bar}{bar} | {n_fmt}/{total_fmt} batches | Elapsed: {elapsed} | Remaining: {remaining}\")\n",
    "            for images, masks in val_loop:\n",
    "                # if early_stopping_counter > 5:\n",
    "                #     print(\"Early stopping triggered.\")\n",
    "                #     break\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                masks = masks.to(device, non_blocking=True).float()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "                early_stopping_counter += 1\n",
    "\n",
    "                val_loop.set_description(f\"Validating. Current Avg. loss: {(val_loss / early_stopping_counter):.4f}\")\n",
    "\n",
    "        # Print epoch results\n",
    "        epoch_loop.write(f\"Epoch {epoch + 1}/{epochs} - Training Loss: {running_loss / len(train_loader):.4f} - Validation Loss: {val_loss / len(val_loader):.4f}\")\n",
    "        \n",
    "\n",
    "# Save/load model\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "    \n",
    "save_model_path = os.path.join(script_dir, 'unet_model.pth')\n",
    "if os.path.exists(save_model_path):\n",
    "    print(\"Loading existing trained model...\")\n",
    "    model.load_state_dict(torch.load(save_model_path))\n",
    "\n",
    "    #predict image and display besides original mask\n",
    "    for i in range(len(test_loader.dataset)):\n",
    "        print(\"Image\", i)\n",
    "        print(\"Image shape:\", test_loader.dataset[i][0].shape)\n",
    "        print(\"Mask shape:\", test_loader.dataset[i][1].shape)\n",
    "        model.to(device)  # Ensure the model is on the correct device\n",
    "        y_pred = model(test_loader.dataset[i][0].unsqueeze(0).to(device, dtype=torch.float))\n",
    "\n",
    "        # Set the most likely class for each pixel\n",
    "        predicted_mask = torch.argmax(y_pred, dim=1).squeeze(0).cpu().detach().numpy()\n",
    "\n",
    "        # Convert predicted mask to RGB\n",
    "        rgb_predicted_mask = train_dataset.class_id_to_rgb(predicted_mask)\n",
    "\n",
    "        # Get the ground truth mask\n",
    "        ground_truth_mask = torch.argmax(test_loader.dataset[i][1], dim=0).cpu().detach().numpy()\n",
    "        rgb_ground_truth_mask = train_dataset.class_id_to_rgb(ground_truth_mask)\n",
    "\n",
    "        # Print shapes for debugging\n",
    "        print(\"Predicted mask shape:\", predicted_mask.shape)\n",
    "        print(\"RGB Predicted mask shape:\", rgb_predicted_mask.shape)\n",
    "        print(\"Ground truth mask shape:\", ground_truth_mask.shape)\n",
    "        print(\"RGB Ground truth mask shape:\", rgb_ground_truth_mask.shape)\n",
    "\n",
    "        # Display the images\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(test_loader.dataset[i][0].cpu().numpy().transpose(1, 2, 0))\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(rgb_ground_truth_mask)\n",
    "        plt.title(\"Ground Truth Mask\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(rgb_predicted_mask)\n",
    "        plt.title(\"Predicted Mask\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Training model...\")\n",
    "    train(model, train_loader, val_loader, criterion, optimizer, device, epochs=3)\n",
    "save_model(model, save_model_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
